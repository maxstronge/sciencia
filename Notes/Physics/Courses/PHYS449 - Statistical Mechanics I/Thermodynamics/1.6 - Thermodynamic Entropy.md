# Entropy:
***
### The Second Law of Thermodynamics:

The consequences of the first law of thermodynamics can be summarized by the statements:

> 1. Energy is conserved in thermal processes
> 2. Heating is a form of energy transfer

There are many processes in nature, however, that do not occur, even though they do not violate the first law. We must take another property of systems into account, and that is the thermodynamic **entropy**. Entropy is another example of a *state function*. One of the remarkable achievements of the 19th century was the reasoning that a state function *must* exist, without any idea of how to measure its value directly.

Recall the two formulations of the second law of thermodynamics discussed so far:

- Kelvin formulation: *No process is possible whose sole result is the complete conversion of energy transferred by heating into work.*
- Clausius formulation: *No process is possible whose sole result is cooling a colder body and heating a hotter body*.

Each of these formulations implies the other, and so they are equivalent. 

There is a more abstract version of the second law that is not based on the heat-engine thought experiment, and is much more convenient in many contexts:

> There exists an additive state function called the *entropy* $S$ that can never decrease in an isolated system.


Because the entropy cannot decrease in an isolated system, we conclude that the entropy is a *maximum* for an isolated system in equilibrium. 

The term *additive* means that if the entropy of two systems are $S_A$ and $S_B$ respectively, the entropy of the combined system is $S=S_A + S_B$. 


The statement of the second law in terms of entropy is applicable *only to isolated systems* - since only one of these exists (the entire universe), the systems of interest in thermodynamics exchange energy with their surroundings. In many cases, the surroundings/environment may be idealized as a large body that does not interact with the rest of the universe - for example, the surroundings of a cup of hot water may be just the atmosphere in that room, rather than the entire rest of the universe. In this case we can treat the *composite* system (system + surroundings) as an isolated system. For the composite system, we have for any process:

$$\DD S_\text{composite} \geq 0$$

where $S_\text{composite}$ is the entropy of the system plus its surroundings.

If a change is reversible, we cannot have $\DD S_\text{composite} >0$, because then the process would violate the second law running in reverse. Hence, the only possibility is that
$$\DD S_\text{composite} = 0 \text{ [reversible processes]}$$

The condition for a process to be reversible requires only that the total entropy of a closed system be constant - the entropies of its parts may increase or decrease so long as there is zero net change in entropy. 


***

### The Second Law and Heat Engines:

A body that can change the temperature of another body without changing its own temperature and without doing any work is known as a *heat bath*, also referred to as a *thermal bath*. The Earth's ocean and atmosphere act as thermal baths under some conditions. 

For pure heating/cooling (no work), the increase in entropy is given by:

$$dS = \left (\pdv{S}{E} \right)_{V,N}dE $$ ^cce99b


In this case, $dE=dQ$ because no work is done. If we express the above partial derivative in terms of $T$, we can rewrite it as ^06a933

$$dS= \frac{dQ}{T}$$
We must emphasize here that [[#^cce99b|the above relation]] only holds for *quasi-static processes*. Note that it implies that **the entropy does not change in quasi-static, adiabatic processes**. 


We can now use this relation to discuss the efficiency of possible heat engines, which was the motivation for the development of much of thermodynamics. We know that an *engine* converts energy from a heat source to do work, and returns to its initial state. According to  [[#^cce99b|the above]], the transfer of energy from a heat source *lowers the entropy of the source*. If the energy transferred is used to do work, the work done must be done on some other system - because the process of doing this work may be quasi-static and adiabatic, the work done need not necessarily involve a change in entropy. But if all the energy transferred were converted into work, the total entropy would decrease, and we would violate the second law. Hence, we arrive at the conclusion summarized in the Kelvin formulation of the second law: **no process is possible whose sole result is the complete conversion of energy into work.**

We need to do something with the energy that was not converted to work! We can end up finding the maximum efficiency of a heat engine:

$$\eta = 1-\frac{T_\text{low}}{T_\text{high}}\qq{} {\text{[maximum thermal efficiency]}}$$

Note that the temperatures in the above are thermodynamic temperatures in Kelvin. A reversible engine with this efficiency is known as a **Carnot engine** - the fact that this is the maximum thermal efficiency can be proven, and this is known as **Carnot's principle**. 

***
### Entropy Changes:

The impetus for developing thermodynamics was the industrial revolution and the efficiency of heat engines. The key to thermodynamics is understanding the role of **entropy changes**. We turn our attention there now:

> **Change in entropy of a solid:**
> 
> The heat capacity of water and solids at room temperatures is independent of temperature to a good approximation. A solid with heat capacity $C$ is taken from an initial temperature $T_1$ to a final temperature $T_2$. What is its change in entropy?
> 
> **Solution:**
> Assume the temperature of the solid is increased by putting the solid in contact with a succession of heat baths at temperatures separated by a small amount, such that we can use the quasi-static result $dS=\frac{dQ}{T}$. Then the entropy change is given by
> $$S_2-S_1=\int^{T_2}_{T_{1}} \frac{dQ}{T}=\int^{T_2}_{T_{1}C(T)}  \frac{dT}{T}$$
> Because the heat capacity $C$ is assumed to be constant, we find $$\Delta S = S_{2}- S_{1}=C\int^{T_2}_{T_{1}} \frac{dT}{T}= C\ln 
 \frac{T_{2}}{T_{1}}.$$

***

### The Fundamental Thermodynamic Relation:

The first law of thermodynamics implies that the internal energy $U$ is a state function. For *any* change of state, the change in $U$ is given by $$\Delta U = Q + W$$ To separate the contributions to $E$ due to heating and work, the constraints on the system must be known. If the change is quasistatic, then the infinitesimal work done is $$dW = -pdV$$ and $$dQ = TdS.$$ Thus, for an infinitesimal change in the energy we have  

$$dU = TdS-PdV$$ ^93265d

This equation relates energy, entropy, and volume. We can alternately interpret [[#^93265d|this relation]] as the *differential form* (for fixed $N$) of the energy equation of state $U=U(S,V,N)$. Because the entropy $S=S(U,V,N)$ is also a state function, and we defined $T$ and $p$ in terms of derivatives of $S$, we may rewrite the above as

$$dS= \frac{1}{T}dU + \frac{P}{T}dV$$
We also have 

$$dS = \left (\pdv{S}{E} \right)_{V,N}dU + \left (\pdv{S}{V} \right)_{U,N} dV + \left (\pdv{S}{N} \right)_{U,V} dN$$

Which is recognizable as the total derivative of the entropy. A comparison of the above two equations gives the familiar results:

$$\left (\pdv{S}{U} \right)_{V,N} = \frac{1}{T}$$

$$\left (\pdv{S}{V} \right)_{U,N} = \frac{p}{T}$$

If we allow $N$ to vary, we can write the differential entropy as 

$$dS = \frac{1}{T}dU + \frac{p}{T}dV$$
If we know the entropy $S$ as a function of $U$ and $V$ (and maybe $N$ if chemical interactions are relevant), we can determine the corresponding responses $T$, $p$, and other variables like $\mu$ if applicable. For this reason, we shall refer to $U, V$, and $N$ as the **natural variables** in which $S$ should be expressed. 

In this context, $S$ can be interpreted as a **thermodynamic potential**, because its various partial derivatives yield the equations of state of the system. 

We can also consider $U$ as a function of $S$ and $V$ , and rewrite the above as:

$$dU = TdS - pdV$$
This is a mathematical statement combining the first and second laws, and is known as the **fundamental thermodynamic relation**. Memorize!!!

Many useful thermodynamic relations can be derived using the FTR. For example, if we regard $U$ as a function of $S$ and $V$, we can write 

$$dU = \left (\pdv{U}{S} \right)_{V,N} dS + \left (\pdv{U}{V} \right)_{S,N} dV + \left[\left (\pdv{U}{N} \right)_{S,V}dN\right]$$

Where the third term is often unnecessary for this course as it factors chemical forces in. We can then easily see by comparison that 

$$\left (\pdv{U}{S} \right)_{V}=T$$

$$-\left (\pdv{U}{V} \right)_{S}=p$$

Note that $U(S,V)$ can also be interpreted as a thermodynamic potential, as we shall see shortly.

***

